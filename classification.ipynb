{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"line-height:2px;border: solid orange\">\n",
    "    <p>\n",
    "    <p style=\"color:blue;font-family:arial;text-align:right;font-size:20\"> Visión por Computador &nbsp;&nbsp;\n",
    "    <p style=\"color:blue;font-family:arial;text-align:right;font-size:16\"> Master en Ciencias de Datos e Ingeniería de Ordenadores   &nbsp;&nbsp;\n",
    "  <p style=\"color:blue;font-family:arial;text-align:right;font-size:16\"> Rosa Mª. Rodríguez Sánchez   &nbsp;&nbsp;\n",
    "    <p style=\"color:blue;font-family:arial;text-align:right;font-size:10\"> Dpto. Ciencias de la Computación e Inteligencia Artificial. &nbsp;&nbsp;\n",
    "    <p style=\"color:blue;font-family:arial;text-align:right;font-size:10\"> ETSIIT. Universidad de Granada   &nbsp;&nbsp;\n",
    "        <p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo 3- Clasificación de peatones\n",
    "\n",
    "## Autores:\n",
    "    -  Juan Emilio Martínez Manjón\n",
    "    -  Antonio David Villegas Yeguas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de la BBDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Módulos\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import Model, Sequential\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Lambda, BatchNormalization, RandomFlip, RandomRotation\n",
    "import random\n",
    "from time import time\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones imagenes positivas:  (128, 64, 3)\n",
      "Dimensiones imagenes negativas:  (128, 64, 3)\n",
      "Numero de imagenes positivas:  400\n",
      "Numero de imagenes negativas:  400\n"
     ]
    }
   ],
   "source": [
    "# Establecemos una semilla\n",
    "random.seed(1234)\n",
    "\n",
    "# Creamos una función que lea todas las imágenes de un directorio\n",
    "# concreto.\n",
    "def load_images(directorio, color=0):\n",
    "    imagenes = []\n",
    "    for filename in os.listdir(directorio):\n",
    "        img = cv2.imread(os.path.join(directorio,filename),color)\n",
    "        if img is not None:\n",
    "            imagenes.append(img)\n",
    "    return imagenes\n",
    "\n",
    "# Leemos las imágenes positivas (con peatones)\n",
    "X_pos = load_images(\"data/classification/pedestrians128x64\",1)\n",
    "y_pos = [1 for i in range(0,len(X_pos))]\n",
    "\n",
    "# Leemos las imágenes negativas (sin peatones)\n",
    "X_neg = load_images(\"data/classification/pedestrians_neg\",1)\n",
    "y_nega = [-1 for i in range(0,len(X_neg))]\n",
    "\n",
    "# El guion de prácticas nos indica que solo debemos usar 400 de las 924\n",
    "# imágenes positivas. Las escogemos aleatoriamente.\n",
    "X_pos = random.sample(X_pos, 400)\n",
    "y_pos = y_pos[0:400]\n",
    "\n",
    "# El conjunto negativo solo tiene 50 imágenes. Debemos aumentar este conjunto\n",
    "# hasta llegar a 400. Para ello redimensionaremos las 50 imágenes a un tamaño de\n",
    "# 512x512. Una vez hecho esto, escogeremos 8 trozos 128x64 de cada imagen\n",
    "# redimensionada.\n",
    "\n",
    "# Redimensionamos las imágenes\n",
    "X_neg_resized = []\n",
    "\n",
    "for im in X_neg:\n",
    "    X_neg_resized.append(cv2.resize(im,(512,512)))\n",
    "\n",
    "# Extraemos 8 trozos 128x64 de cada imagen\n",
    "X_neg = []\n",
    "\n",
    "for im in X_neg_resized:\n",
    "    for i in range (0,8):\n",
    "\n",
    "        # Escogemos una fila y columna inicial aleatoria\n",
    "        random_init_row = random.randint(0,512-128)\n",
    "        random_init_col = random.randint(0,512-64)\n",
    "\n",
    "        # Extraemos la imagen\n",
    "        extraida = im[random_init_row:random_init_row+128, random_init_col:random_init_col+64]\n",
    "        X_neg.append(extraida)\n",
    "\n",
    "y_nega = [-1 for i in range(0,len(X_neg))]\n",
    "\n",
    "print(\"Dimensiones imagenes positivas: \",X_pos[0].shape)\n",
    "print(\"Dimensiones imagenes negativas: \",X_neg[0].shape)\n",
    "print(\"Numero de imagenes positivas: \",len(X_pos))\n",
    "print(\"Numero de imagenes negativas: \",len(X_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación usando SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones HOG_X_pos:  (400, 4200)\n",
      "Dimensiones HOG_X_neg:  (400, 4200)\n"
     ]
    }
   ],
   "source": [
    "# Función que calcula el HOG de una imagen\n",
    "def HOG(imagen):\n",
    "\n",
    "    # Pasamos la imagen a float (escala 0-1)\n",
    "    imagen = np.float32(imagen) / 255.0\n",
    "\n",
    "    # Comenzamos obteniendo las imágenes gradiente. Para ello\n",
    "    # convolucionamos la imagen con kernels Sobel 1D.\n",
    "\n",
    "    Gx = cv2.Sobel(imagen, cv2.CV_32F, 1, 0, ksize=1)\n",
    "    Gy = cv2.Sobel(imagen, cv2.CV_32F, 0, 1, ksize=1)\n",
    "\n",
    "    # Calculamos la magnitud\n",
    "    magnitud = np.sqrt(Gx**2 + Gy**2)\n",
    "\n",
    "    # Calculamos la orientacion\n",
    "    orientacion = np.abs(np.arctan2(Gy,Gx) * 180/np.pi)\n",
    "\n",
    "    # Ahora debemos calcular un histograma de orientación de gradiente\n",
    "    # por cada célula 8x8 de nuestra imagen. Para ello crearemos una\n",
    "    # matriz de listas que iremos rellenando.\n",
    "\n",
    "    hog = [[0 for x in range(int(imagen.shape[1] / 8))] for y in range(int(imagen.shape[0] / 8))]\n",
    "\n",
    "    # Recorremos cada célula\n",
    "    for indice1,r in enumerate(range(0, imagen.shape[0], 8)):\n",
    "        for indice2,c in enumerate(range(0, imagen.shape[1], 8)):\n",
    "\n",
    "            # Inicializamos el hog de la célula actual\n",
    "            hog_aux = [0.0 for i in range(0,10)]\n",
    "            hog_angles = [10,30,50,70,90,110,130,150,170,180]\n",
    "            mag_aux = magnitud[r:r+8,c:c+8,1]\n",
    "            ori_aux = orientacion[r:r+8,c:c+8,1]\n",
    "\n",
    "            # Recorremos la célula\n",
    "            for i in range(mag_aux.shape[0]):\n",
    "                for j in range(mag_aux.shape[1]):\n",
    "\n",
    "                    # Vemos cual es el ángulo más cercano de la lista de hog_angles\n",
    "                    indx = (np.abs(hog_angles - ori_aux[i][j])).argmin()\n",
    "\n",
    "                    # Si coincide con el ángulo, añadimos la magnitud del pixel al hog\n",
    "                    if (ori_aux[i][j] == hog_angles[indx]):\n",
    "                        hog_aux[indx] += mag_aux[i][j]\n",
    "\n",
    "                    # Si no coincide, dividimos la magnitud entre los ángulos adyacentes\n",
    "                    else:\n",
    "                        # Si el ángulo es menor\n",
    "                        if (ori_aux[i][j] < hog_angles[indx]):\n",
    "\n",
    "                            hog_aux[indx-1] += mag_aux[i][j]*(hog_angles[indx]-ori_aux[i][j])/(hog_angles[indx] - hog_angles[indx-1])\n",
    "\n",
    "                            hog_aux[indx] += mag_aux[i][j]*(ori_aux[i][j] - hog_angles[indx-1])/(hog_angles[indx] - hog_angles[indx-1])\n",
    "\n",
    "                        # Si el ángulo es mayor\n",
    "                        else:\n",
    "\n",
    "                            hog_aux[indx] += mag_aux[i][j]*(hog_angles[indx+1]-ori_aux[i][j])/(hog_angles[indx+1] - hog_angles[indx])\n",
    "\n",
    "                            hog_aux[indx+1] += mag_aux[i][j]*(ori_aux[i][j] - hog_angles[indx])/(hog_angles[indx+1] - hog_angles[indx])\n",
    "\n",
    "            # Almacenamos en hog los valores de hog_aux\n",
    "            hog[indice1][indice2] = hog_aux\n",
    "\n",
    "    # Agrupamos los histogramas/célula en bloques de histogramas. Cada bloque estará formado\n",
    "    # por 4 células.\n",
    "    hog_bloques = []\n",
    "    for i in range(0, int(imagen.shape[0] / 8) - 1):\n",
    "        for j in range(0, int(imagen.shape[1] / 8) - 1):\n",
    "\n",
    "            aux = []\n",
    "\n",
    "            aux = aux + hog[i][j]\n",
    "            aux = aux + hog[i][j+1]\n",
    "            aux = aux + hog[i+1][j]\n",
    "            aux = aux + hog[i+1][j+1]\n",
    "\n",
    "            hog_bloques.append(aux)\n",
    "\n",
    "    # Normalizamos el hog por bloques\n",
    "    for i,bloque in enumerate(hog_bloques):\n",
    "\n",
    "        # Calculamos el modulo del bloque actual\n",
    "        modulo = 0.0\n",
    "        for el in bloque:\n",
    "            modulo = modulo + el**2\n",
    "\n",
    "        modulo = math.sqrt(modulo + 0.01)\n",
    "\n",
    "        # Dividimos el bloque actual entre el módulo\n",
    "        hog_bloques[i] = [x / modulo for x in bloque]\n",
    "\n",
    "    # Concatenamos todos los elementos del hog de bloques\n",
    "    # para obtener el vector de descriptores\n",
    "    vector_descriptores = [x for l in hog_bloques for x in l]\n",
    "\n",
    "    # Normalizamos el vector de descriptores\n",
    "    modulo = 0.0\n",
    "    for el in vector_descriptores:\n",
    "        modulo = modulo + el**2\n",
    "\n",
    "    modulo = math.sqrt(modulo + 0.01)\n",
    "\n",
    "    # Dividimos cada elemento del vector entre el módulo\n",
    "    vector_descriptores = [x / modulo for x in vector_descriptores]\n",
    "\n",
    "    return vector_descriptores\n",
    "\n",
    "\n",
    "\n",
    "# Creamos HOG_X_pos y HOG_X_neg a partir de X_pos y X_neg.\n",
    "# Empezamos con HOG_X_pos\n",
    "HOG_X_pos = []\n",
    "\n",
    "for imagen in X_pos:\n",
    "    HOG_X_pos.append(HOG(imagen))\n",
    "\n",
    "HOG_X_pos = np.array([np.array(xi) for xi in HOG_X_pos])\n",
    "\n",
    "print(\"Dimensiones HOG_X_pos: \",HOG_X_pos.shape)\n",
    "\n",
    "\n",
    "# Ahora HOG_X_neg\n",
    "HOG_X_neg = []\n",
    "\n",
    "for imagen in X_neg:\n",
    "    HOG_X_neg.append(HOG(imagen))\n",
    "\n",
    "HOG_X_neg = np.array([np.array(xi) for xi in HOG_X_neg])\n",
    "\n",
    "print(\"Dimensiones HOG_X_neg: \",HOG_X_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de observaciones training:  640\n",
      "Numero de observaciones test:  160\n"
     ]
    }
   ],
   "source": [
    "# Establecemos una semilla\n",
    "random.seed(1234)\n",
    "\n",
    "# Creamos la matriz X y el vector y\n",
    "X = np.concatenate([HOG_X_pos,HOG_X_neg])\n",
    "y = np.concatenate([y_pos,y_nega])\n",
    "\n",
    "# Hacemos una división en training y test\n",
    "ntrain = round(0.8*len(y))\n",
    "ntest = len(X)-ntrain\n",
    "\n",
    "print(\"Numero de observaciones training: \",ntrain)\n",
    "print(\"Numero de observaciones test: \", ntest)\n",
    "\n",
    "idx = np.random.permutation(np.arange(len(y)))\n",
    "X_train= X[idx[0:ntrain],:]\n",
    "y_train=y[idx[0:ntrain]]\n",
    "X_test= X[idx[ntrain+1:len(y)],:]\n",
    "y_test=y[idx[ntrain+1:len(y)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training:  1.0\n",
      "Accuracy test:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<AxesSubplot:title={'center':'Matriz confusión test'}>,\n",
       " <AxesSubplot:title={'center':'Matriz confusión test'}>,\n",
       " Text(0.5, 1.0, 'Matriz confusión test'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creamos un clasificador SVM y lo entrenamos con nuestros datos de\n",
    "# entrenamiento.\n",
    "\n",
    "m=SVC()\n",
    "m.fit(X_train,y_train)\n",
    "\n",
    "# Predecimos usando los datos de entrenamiento y de test\n",
    "y_pred_train=m.predict(X_train)\n",
    "y_pred_test=m.predict(X_test)\n",
    "\n",
    "# Obtenemos la accuracy en training y en test\n",
    "training_accuracy = np.sum(y_train == y_pred_train) / len(y_pred_train)\n",
    "test_accuracy = np.sum(y_test == y_pred_test) / len(y_pred_test)\n",
    "\n",
    "print(\"Accuracy training: \",training_accuracy)\n",
    "print(\"Accuracy test: \",test_accuracy)\n",
    "\n",
    "# Mostramos las matrices de confusión\n",
    "matriz_training = confusion_matrix(y_train,y_pred_train)\n",
    "matriz_test = confusion_matrix(y_test,y_pred_test)\n",
    "\n",
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(121),sn.heatmap(matriz_training, annot=True,fmt=\"d\"),plt.title('Matriz confusión training')\n",
    "plt.subplot(122),sn.heatmap(matriz_test, annot=True,fmt=\"d\"),plt.title('Matriz confusión test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación usando CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Función que muestra la evolución de las accuracy de train y validación\n",
    "## durante el entrenamiento.\n",
    "def mostrar_evolucion(hist):\n",
    "\n",
    "    loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.legend(['Training loss', 'Validation loss'])\n",
    "    plt.show()\n",
    "\n",
    "    acc = hist.history['binary_accuracy']\n",
    "    val_acc = hist.history['val_binary_accuracy']\n",
    "    plt.plot(acc)\n",
    "    plt.plot(val_acc)\n",
    "    plt.legend(['Training accuracy', 'Validation accuracy'])\n",
    "    plt.show()\n",
    "\n",
    "# Función que entrena y calcula las métricas de un modelo usando Fine Tuning\n",
    "def train_model(base_model, input_layer, training, validation, test, logits=True):\n",
    "\n",
    "    # Creamos un modelo secuencial que usaremos para Data Augmentation\n",
    "    data_augmentation = Sequential([\n",
    "        RandomFlip(),\n",
    "        RandomRotation(0.1)\n",
    "    ])\n",
    "\n",
    "    # Creamos el modelo final\n",
    "    model = Sequential([\n",
    "        input_layer,\n",
    "        data_augmentation,\n",
    "        base_model,\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "    # Compilamos el modelo\n",
    "    model.compile(\n",
    "        optimizer=Adam(),\n",
    "        loss=BinaryCrossentropy(from_logits=logits),\n",
    "        metrics=[BinaryAccuracy()]\n",
    "    )\n",
    "\n",
    "    # Entrenamos el modelo usando callbacks para parar de entrenar\n",
    "    # si la validación se aleja demasiado del entrenamiento\n",
    "    callback = EarlyStopping(patience=3,restore_best_weights=True)\n",
    "    start = time()\n",
    "    history = model.fit(training,\n",
    "                    epochs=40,\n",
    "                    validation_data=validation,\n",
    "                    callbacks=callback)\n",
    "    first_training_time = time()-start\n",
    "    mostrar_evolucion(history)\n",
    "\n",
    "    # Descongelamos el modelo base\n",
    "    base_model.trainable = True\n",
    "\n",
    "    # Compilamos el modelo de nuevo usando un learning rate bajo\n",
    "    model.compile(\n",
    "        optimizer=Adam(1e-5),\n",
    "        loss=BinaryCrossentropy(from_logits=logits),\n",
    "        metrics=[BinaryAccuracy()]\n",
    "    )\n",
    "\n",
    "    # Entrenamos el modelo entero\n",
    "    start = time()\n",
    "    history = model.fit(training,\n",
    "                    epochs=100,\n",
    "                    validation_data=validation,\n",
    "                    callbacks=callback)\n",
    "    second_training_time = time()-start\n",
    "    mostrar_evolucion(history)\n",
    "\n",
    "    # Predecimos y calculamos una accuracy\n",
    "    score = model.evaluate(test)\n",
    "\n",
    "    return first_training_time, second_training_time, score[1], model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de observaciones training:  262\n",
      "Numero de observaciones validacion:  66\n",
      "Numero de observaciones test:  160\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.concatenate([X_pos,X_neg])\n",
    "y_nega = [0 for i in range(0,len(y_nega))]\n",
    "y = np.concatenate([y_pos,y_nega])\n",
    "\n",
    "\n",
    "# Hacemos una división en training y test\n",
    "ntrain = round(0.8*len(y))\n",
    "ntest = len(X)-ntrain\n",
    "\n",
    "\n",
    "idx = np.random.permutation(np.arange(len(y)))\n",
    "X_train_val= X[idx[0:ntrain],:]\n",
    "y_train_val=y[idx[0:ntrain]]\n",
    "X_test= X[idx[ntrain+1:len(y)],:]\n",
    "y_test=y[idx[ntrain+1:len(y)]]\n",
    "\n",
    "ntrain = round(0.8*len(y_train))\n",
    "nval = len(X_train)-ntrain\n",
    "\n",
    "idx = np.random.permutation(np.arange(len(y_train_val)))\n",
    "X_train= X_train_val[idx[0:ntrain],:]\n",
    "y_train=y_train_val[idx[0:ntrain]]\n",
    "X_val= X_train_val[idx[ntrain+1:len(y_train_val)],:]\n",
    "y_val=y_train_val[idx[ntrain+1:len(y_train_val)]]\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Numero de observaciones training: \",ntrain)\n",
    "print(\"Numero de observaciones validacion: \",nval)\n",
    "print(\"Numero de observaciones test: \", ntest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda_52 (Lambda)          (None, 128, 64, 3)        0         \n",
      "                                                                 \n",
      " sequential_92 (Sequential)  (None, 128, 64, 3)        0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 512)               14714688  \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,717,249\n",
      "Trainable params: 1,537\n",
      "Non-trainable params: 14,715,712\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/40\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.9425 - binary_accuracy: 0.4885 - val_loss: 1.4259 - val_binary_accuracy: 0.6313\n",
      "Epoch 2/40\n",
      "9/9 [==============================] - 17s 2s/step - loss: 0.6594 - binary_accuracy: 0.6336 - val_loss: 1.0997 - val_binary_accuracy: 0.7162\n",
      "Epoch 3/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.4711 - binary_accuracy: 0.7176 - val_loss: 0.9458 - val_binary_accuracy: 0.7480\n",
      "Epoch 4/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.4176 - binary_accuracy: 0.7786 - val_loss: 0.8046 - val_binary_accuracy: 0.7719\n",
      "Epoch 5/40\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.3155 - binary_accuracy: 0.8702 - val_loss: 0.6911 - val_binary_accuracy: 0.7958\n",
      "Epoch 6/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.2784 - binary_accuracy: 0.8626 - val_loss: 0.6177 - val_binary_accuracy: 0.8276\n",
      "Epoch 7/40\n",
      "9/9 [==============================] - 17s 2s/step - loss: 0.2157 - binary_accuracy: 0.9084 - val_loss: 0.5481 - val_binary_accuracy: 0.8355\n",
      "Epoch 8/40\n",
      "9/9 [==============================] - 17s 2s/step - loss: 0.2205 - binary_accuracy: 0.9046 - val_loss: 0.4851 - val_binary_accuracy: 0.8568\n",
      "Epoch 9/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.1605 - binary_accuracy: 0.9504 - val_loss: 0.4377 - val_binary_accuracy: 0.8674\n",
      "Epoch 10/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.1840 - binary_accuracy: 0.9275 - val_loss: 0.3977 - val_binary_accuracy: 0.8806\n",
      "Epoch 11/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.1184 - binary_accuracy: 0.9618 - val_loss: 0.3718 - val_binary_accuracy: 0.8859\n",
      "Epoch 12/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.1456 - binary_accuracy: 0.9542 - val_loss: 0.3507 - val_binary_accuracy: 0.8939\n",
      "Epoch 13/40\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.1358 - binary_accuracy: 0.9466 - val_loss: 0.3160 - val_binary_accuracy: 0.9019\n",
      "Epoch 14/40\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.1057 - binary_accuracy: 0.9733 - val_loss: 0.2986 - val_binary_accuracy: 0.9072\n",
      "Epoch 15/40\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.1110 - binary_accuracy: 0.9618 - val_loss: 0.2794 - val_binary_accuracy: 0.9098\n",
      "Epoch 16/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.1004 - binary_accuracy: 0.9656 - val_loss: 0.2614 - val_binary_accuracy: 0.9204\n",
      "Epoch 17/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.1231 - binary_accuracy: 0.9466 - val_loss: 0.2471 - val_binary_accuracy: 0.9284\n",
      "Epoch 18/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.1056 - binary_accuracy: 0.9580 - val_loss: 0.2295 - val_binary_accuracy: 0.9416\n",
      "Epoch 19/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.0922 - binary_accuracy: 0.9695 - val_loss: 0.2181 - val_binary_accuracy: 0.9469\n",
      "Epoch 20/40\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.0734 - binary_accuracy: 0.9695 - val_loss: 0.2072 - val_binary_accuracy: 0.9469\n",
      "Epoch 21/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.0814 - binary_accuracy: 0.9695 - val_loss: 0.1974 - val_binary_accuracy: 0.9496\n",
      "Epoch 22/40\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.0700 - binary_accuracy: 0.9809 - val_loss: 0.1883 - val_binary_accuracy: 0.9496\n",
      "Epoch 23/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.1007 - binary_accuracy: 0.9542 - val_loss: 0.1770 - val_binary_accuracy: 0.9496\n",
      "Epoch 24/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.0746 - binary_accuracy: 0.9809 - val_loss: 0.1658 - val_binary_accuracy: 0.9549\n",
      "Epoch 25/40\n",
      "9/9 [==============================] - 18s 2s/step - loss: 0.0660 - binary_accuracy: 0.9847 - val_loss: 0.1611 - val_binary_accuracy: 0.9576\n",
      "Epoch 26/40\n",
      "9/9 [==============================] - 19s 2s/step - loss: 0.0919 - binary_accuracy: 0.9733 - val_loss: 0.1524 - val_binary_accuracy: 0.9602\n",
      "Epoch 27/40\n",
      "4/9 [============>.................] - ETA: 4s - loss: 0.0730 - binary_accuracy: 0.9844"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m vgg16\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      6\u001b[0m preprocesado \u001b[38;5;241m=\u001b[39m Lambda(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mapplications\u001b[38;5;241m.\u001b[39mvgg16\u001b[38;5;241m.\u001b[39mpreprocess_input, input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m first_training_time, second_training_time, test_accuracy, modelo_vgg16 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvgg16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocesado\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(base_model, input_layer, training, validation, test, logits)\u001b[0m\n\u001b[1;32m     49\u001b[0m callback \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 51\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m first_training_time \u001b[38;5;241m=\u001b[39m time()\u001b[38;5;241m-\u001b[39mstart\n\u001b[1;32m     56\u001b[0m mostrar_evolucion(history)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg16 = tf.keras.applications.VGG16(include_top = False, weights = \"imagenet\",\n",
    "                                    pooling = \"avg\")\n",
    "\n",
    "vgg16.trainable = False\n",
    "\n",
    "preprocesado = Lambda(tf.keras.applications.vgg16.preprocess_input, input_shape = (128,64,3))\n",
    "\n",
    "first_training_time, second_training_time, test_accuracy, modelo_vgg16 = train_model(vgg16, preprocesado, \n",
    "                                                                                   train_dataset,\n",
    "                                                                                   validation_dataset,\n",
    "                                                                                   test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = tf.keras.applications.ResNet50(include_top = False, weights = \"imagenet\",\n",
    "                                    pooling = \"avg\")\n",
    "\n",
    "resnet50.trainable = False\n",
    "\n",
    "preprocesado = Lambda(tf.keras.applications.resnet50.preprocess_input, input_shape = (128,64,3))\n",
    "\n",
    "first_training_time, second_training_time, test_accuracy, modelo_resnet = train_model(resnet50, preprocesado, \n",
    "                                                                                   train_dataset,\n",
    "                                                                                   validation_dataset,\n",
    "                                                                                   test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception = tf.keras.applications.Xception(include_top = False, weights = \"imagenet\",\n",
    "                                    pooling = \"avg\")\n",
    "\n",
    "xception.trainable = False\n",
    "\n",
    "preprocesado = Lambda(tf.keras.applications.xception.preprocess_input, input_shape = (128,64,3))\n",
    "\n",
    "first_training_time, second_training_time, test_accuracy, modelo_resnet = train_model(xception, preprocesado, \n",
    "                                                                                   train_dataset,\n",
    "                                                                                   validation_dataset,\n",
    "                                                                                   test_dataset)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
